# Operating System (운영체제)

이 글은 [JaeYeopHan/OS](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS) 글과 [Operating System Concept/SILBERSCHATZ](https://m.search.naver.com/search.naver?sm=mtp_hty.top&where=m&query=Operating+System#api=%3F_lp_type%3Dcm%26col_prs%3Dcsa%26format%3Dtext%26nqx_theme%3D%257B%2B%2522theme%2522%253A%257B%2522main%2522%253A%257B%2522name%2522%253A%2522book_info%2522%252C%2522os%2522%253A7218891%252C%2522pkid%2522%253A20000%257D%257D%2B%257D%26query%3DOperating%2BSystem%26sm%3Digr_brg%26tab%3Dinfo%26tab_prs%3Dcsa%26where%3Dbridge&_lp_type=cm)를 참고하여 작성하였음을 밝힙니다.

<hr>

## 목차

- [프로세스](#프로세스)
	- 프로세스 상태
    - PCB
- [스레드](#스레드)
- [멀티 스레딩 프로그래밍](#멀티-스레딩-프로그래밍)
	- 멀티 스레드 vs 멀티 프로세스
- [스케줄러](#스케줄러)
	- 장기스케줄러
    - 단기스케줄러
    - 중기스케줄러
- [문맥교환](#문맥-교환)
- [프로세스간 통신](#프로세스간-통신)
	- 공유메모리
    - 메시지전달
- [RPC](#원격-프로시저-호출)
- [CPU 스케줄러](#CPU-스케줄러)
- [동기 vs 비동기](#동기-vs-비동기)

</br>
<hr>
</br>

## 프로세스 

</br>
프로세스란 실행 중인 프로그램이다. 
프로세스는 텍스트 섹션으로 알려진 프로그램 코드 이상이다. 

<img width="294" alt="image" src="https://user-images.githubusercontent.com/33486820/56946789-1f735880-6b66-11e9-8eec-76c1fbe165e6.png"> 


- 스택: 복귀주소와 로컬 변수 와 같은 임시적인 자료를 가진다
- 데이터 섹션: 전역변수 수록
- 힙: 실행정에 동적으로 할당 되는 메모리인 힙  

함수 호출시 스택, malloc등 동적할당 시 힙을 사용한다  
</br>

#### 프로그램은 프로세스이다?

</br>
프로그램 자체는 프로세스가 아니다.

- 프로그램: 명령어 리스트를 내용으로 가진 디스크에 저장된 파일 , Passive entity(수동적 존재)
- 프로세스: 다음에 실행할 명령어를 지정하는 프로그램 카운터 및 관련된 자원의 집합을 가짐,  Active entity(능동적 존재)
즉, 실행파일 (.exe , .out) 과 같은 파일이 메모리에 적재될때 프로그램은 프로세스가 된다.  

두 프로세스가 하나의 프로그램에 연관될수 있지만 별도의 실행 순서로 간주한다.

</br>

## 프로세스 상태

</br>
<img width="1222" alt="image" src="https://user-images.githubusercontent.com/33486820/56947153-3b2b2e80-6b67-11e9-93b6-b0cdfe7b278f.png">

어느 한 순간에 하나의 processor 상에서는 오직 하나의 프로세스만이 실행된다.  

</br>

## PCB(프로세스 제어 블록) 

</br>
프로세스는 PCB으로 운영체제에 의해 표현이된다.  
<img width="174" alt="image" src="https://user-images.githubusercontent.com/33486820/56947282-a5dc6a00-6b67-11e9-9af1-fc74ce0003f6.png">  

> PCB 구성 

- 프로세스 상태 : 현재 프로세스의 위의 5개의 상태의 정보를 나타낸다.
- 프로세스 번호(PID)
- 프로그램 카운터(PC): 이 프로세스가 다음에 실행할 명령어의 주소를 가르킨다.
- CPU 레지스터
- CPU 스케줄링 정보: 프로세스 우선순위, 스케줄 큐에 대한 포인터와 다른 스케줄 매개변수들을 포함
- 메모리에 관한 정보
- accountin(회계) 정보: CPU 사용된 양과 사용된 실제 시간, 시간제한, 계정번호, job 또는 프로세스 번호등을 포함한다.
- 입출력 상태 정보  
  
 </br> 
 
## 스레드

  </br>
스레드는 프로세스의 실행단위 이다. 프로세스가 하나의 실행 스레드를 실행하는 프로그램이다.
한 프로세스가 여러 실행 스레드를 가질 수 있도록 하여 한순간에 하나 이상의 일을 실행할 수 있게 한다.  
스레드를 지원하는 시스템에서 PCB는 각 스레드에 관한 정보를 포함하도록 확장된다.  
한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유 할 수 있다. 

> 스레드 구성
- 스레드 ID
- 프로그램 카운터
- 레지스터 집합
- 스택

같은 프로세스에 속한 다른 스레드와 코드, 데이터섹션  그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유한다. 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화 하여 수행 능력을 향상시키는 것을 멀티 스레딩이라고 한다.이 경우 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 가지고 있다.

> Q) 스택을 스레드마다 독립적으로 할당해야하는 이유는?  

스택은 함수 호출시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간 이므로 **스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다 것이고 이는 독립적인 실행 흐름이 추가되는 것**이다. 따라서 스레드 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

> Q) PC Register 를 스레드마다 독립적으로 할당하는 이유는?

PC값은 스레드가 명령어의 어디까지 수행하였는지를 알수있다. 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다.따라서 PC레지스터를 독립적으로 할당한다.

</br>

<hr>

## 멀티 스레딩 프로그래밍

#### 등장배경 

</br>

하나의 응용 프로그램이 여거 개의 비슷한 작업들을 실행할 필요가있는 상황이 있다. 예를 들어 웹 서버는 클라이언트로 부터 웹 페이지, 이미지, 영상 등에 대한 요청을 받는다. 이때 이전의 보편화 된 방식으로는 서버에 서비스 요청이 들어오면 요청을 수신하는 프로세스가 실행하여 클라이언트에게 제공할 별도의 프로세스를 생성하는 것이다. 하지만 **프로세스 생성 작업은 많은 시간을 소비하고 많은 자원을 필요로 하는 작업이다, 즉 많은 오버헤드가 발생한다.** 그렇기에 프로세스 내부에 여러 스레드를 만들어 나가는 것이 효율 적이다.

</br>

> 참고) RPC 서버들은 대부분 멀티 스레드 시스템으로 구현된다. 서버가 메시지를 받게 되면 그를 서비스해주기 위한 새로운 스레드를 만든다.  

#### 장점

</br>

- 응답성 : 대화형 응용을 멀티 스레드화 하면 응용 프로그램의 일부분이 봉쇄되거나, 또는 응용 프로그램이 긴 작업을 실행하더라도 프로그램의 실행이 계속되는 것을 허용함으로써 사용자에 대한 응답성을 증가 시킨다. 예를 들면, 다중 스레드 웹 브라우저는 한 스레드가 이미지 파일을 로드하고 있는 동안 다른 스레드에서 사용자와의 상호작용이 가능하다.  

- 자원공유: 프로세스는  명시적으로 공유 메모리 또는 메시지전달 기법을 통해서만 자원을 공유할 수 있다. 그러나 스레드는 자동적으로 **그들이 속한 프로세스의 자원들과 메모리를 공유한다.** 코드와 데이터 공유의 이점은 한 응용 프로그램이 같은 주소 공간내에 여러 개의 다른 작업을 하는 스레드를 가질 수 있다는 점이다.  

- 경제성: 프로세스를 할당하는 것보다 스레드를 여러개 할당하는 것이 오버헤드가 적다. 그리고 스레드의 context switch(문맥 교환)은 프로세스의 문맥교환과 달리 **캐시메모리를 비울 필요가 없기 때문에 빠르다.**  

- 규모가변성: 멀티 프로세서 구조에서 더욱 좋다. 스레드가 병렬로 실행할 수 있기 떄문이다.  

</br>

#### 단점

</br>

멀티 프로세스 기반으로 프로그래밍 시 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일 이없었지만 멀티스레딩 기반 프로그래밍시 **스레드는 그들이 속한 프로세스의 자원들과 메모리를 공유하기 때문에** 이 부분을 신경 써주어야 한다. 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다.  
</br>
그렇기 때문에 멀티스레딩 환경에서는 **동기화 작업** 이 필요하다. 동기화를 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것이다. 하지만 이로 인해 **DeadLock**이 발생하여 성능이 저하될 가능성이 높다. 그러므로 locking 기법을 통해 DeadLock을 제어해야한다.  

</br>

#### 멀티 스레드 모델

</br>

- 다대일 모델(Many-to-One Model)
- 일-대-일 모델(One-to-One Model)
- 다-대-다 모델(Many-to-Many Model)

</br>

## 멀티 스레드 vs 멀티 프로세스

</br>

|   |장점|단점|
|:---|:---|:---|
|멀티스레드|멀티프로세스 보다 적은 메모리 공간 차지,문맥전환이 빠르다|오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제(서로 스레드가 동일 자원에 접근) 있다.|
|멀티프로세스|하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다.|멀테스레드보다 많은 메모리 공간과 CPU시간을 차지한다|

> 결론) 두가지는 동시에 여러 작업을 수행한다는 점에서 같지만 정용 해야하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야한다. 


</br>

<hr>

## 프로세스 스케줄링 

 </br> 
멀티 프로그래밍(Multi Programming) 
- CPU 이용을 최대화 하기 위하여 항상 어떤 프로세스가 실행중이도록 하는 것 이다.

시분할(Time-Sharing)
- 멀티프로그래밍이 시행되어 동시에 여러 프로세스가 실행될때 한번의 하나의 프로세스가 작동하지만 CPU를 빈번하게 교체(전환) 하여 동시처럼 느껴지게 하는 것 이다.  
(시분할 시스템의 경우 장기 스케줄러가 없고 곧바로 메모리에 올라가 ready 상태가 된다)

프로세스 스케줄러(Process Scheduler)
- CPU에서 실행 가능한 여러 프로세스들 중에서 하나의 프로세스를 선택한다.  

</br> 

## 스케줄링 큐 

</br>
프로세스가 시스템에 들어오면 job큐에 놓여진다. 주메모리(RAM)에 존재를 하며 실행을 대기하는 프로세스들은 준비완료 큐(ready queue)라 불리는 리스트 상에 유지된다.  
이때 PCB는 준비완료 큐에 있는 다음 프로세스를 가르키는 포인터 필드를 가진다.  


<img width="680" alt="image" src="https://user-images.githubusercontent.com/33486820/56963717-932c5a00-6b94-11e9-872a-41ccec0da075.png">
</br>

## 스케줄러  

</br>

> 프로세스를 스케줄링 하기 위한 Queue의 3가지 종류

- Job Queue: 현재 시스템 내에있는 모든 프로세스의 집합
- Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device Queue: Device I/O 작업을 대기하고 있는 프로세스의 집합

</br>

> 3가지 Queue에 프로세스들을 넣고 빼주는 스케줄러의 3가지 종류
- 장기스케줄러
- 단기스케줄러
- 중기스케줄러 

</br>

### 장기스케줄러(Long-term scheduler or Job scheduler)

</br>
프로세스를 선택하여 실행하기 위해 메모리로 적재한다. 메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시적으로 저장된다. 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결정하는 역할 을 한다. 


- 메모리와 디스크 사이의 스케줄링을 담당
- 프로세스에 메모리 및 각종 리소스를 할당
- 멀티프로그래밍의 정도(메모리에 있는 프로세스들의 수(degree of multiprogramming))를 제어한다.
- 평균 프로세스 이탈률(Average Departure Rate)와 같아야한다
- 프로세스의 상태
	- New(생성) -> Ready Queue(메모리 내)

> 참고) 메모리에 프로그램이 너무 많이 올라가도,너무 적게 올라가도 성능이 좋지 않다.

</br>

### 단기스케줄러(Short-term scheduler or CPU scheduler)

</br>
CPU 스케줄러라고 도 불린다. 실행 준비가 완료되어있는 프로세스들 중에서 선택하여 이들 중 하나에게 CPU

- CPU와 메모리 사이의 스케줄링을 담당
- Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 실행(running) 시킬지 결정.
- 프로세스에 CPU를 할당(Scheduler Dispatch)
- 프로세스의 상태
	- Rady -> Running -> Waiting -> Ready  
    
    
</br>

### 중기스케줄러(Medium-term scheduler or Swapper)

</br>
메모리에서 프로세들을 제거하여, 즉 CPU를 위한 경쟁에서 제거하여 멀티프로그래밍의 정도를 제어한다. 추후에 프로세스를 메모리로 불러와서 중단되었던 지점에서부터 실행을 재개한다. 이러한 기법을 스와핑(swapping)이라고 한다.  
스와핑은 프로세스 혼합 상태를 개선 하기 위해 혹은 메모리 요구 변화가 가용 메모리를 초과하여 메모리를 비우기 위하여 필요하다.  

- 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄(swapping)
- 프로세스에게서 memory를 deallocate
- 멀티프로그래밍의 정도(메모리에 있는 프로세스들의 수(degree of multiprogramming))를 제어한다.
- 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러
- 프로세스 상태
	- Ready -> Sunspended  
    

> Process state - suspended

Suspended(stopped) : 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 swap out 된다. blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 ready state 로 돌아갈 수 있지만 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다.  

</br>

<hr>

## 문맥 교환(Context Switch)

</br>
현재 프로세스 상태(Process State)를 저장하고 다른 프로세스 상태를 가지고 오는 것이다.

- 문맥(Context)는 PCB에 표현된다.
- CPU 레지스터 값, 프로세스 상태, 메모리 관리 정보등 포함한다.
- 사용자,커널 모드 상관없이 아래 작업을 수행한다.
	- CPU현재 상태 저장(state save)
    - 나중에 연산 재게 위해 상채복구 작업(state restore)
- 순수한 오버헤드
- 문맥교환이 일어나는 동안에는 아무런 작업을 할 수 없으므로 빠르게 처리되어야한다.
- 현재 레지스터 집합에 대한 포인터를 변경하기만 하면된다. 



</br>

## 프로세스간 통신(Interprocess Communication)  

</br>
운영체제 내에서 실행되는 병행 프로세스들은 독립적이거나 또는 협력적인 프로세스들이다. 
이때 다른 프로세스들과 자료를 공유하는 프로세스는 상호 협력적인 프로세스이다.  

- 정보공유: 동일한 파일에 대한 병행적 접근 할 수 있는 환경 제공
- 계산 가속화: 빠른 task 처리를 위해 subtask로 분활 하여 병렬 처리
- 모듈성(Modularity): 시스템 기능을 별도의 프로세스들 또는 스레들로 나누어 시스템 구성
- 편의성: 개별 사용자들이 동시에 여러 작업을 가질 수 있다.

> 프로세스 통신의 두가지 모델

- 공유메모리
- 메시지전달

</br>

### 공유 메모리 시스템(Shared Memory System)

</br>
프로세스 간 통신에서는 통신하는 프로세스들이 공유 메모리영역을 구축한다. 
생산자 프로세스는 정보를 생산하고 소비자 프로세스는 정보를 소비한다.  
생산자-소비자 문제의 해결책이 된다.  
생산자와 소비자 사이에 **유한버퍼,무한버퍼** 에따라 둘 사이가 동기화가 되어 생산하지 않는 항목을 소비자는 소비하려고 하는 문제가 발생하지 않는다.

</br>

### 메시지 전달 시스템(Message-Passing System)

</br>
동일한 주소 공간을 공유하지 않고도 프로세스들이 통신하고 그들의 동작을 동기화 할 수 있도록 허용하는 기법을 제공한다. 통신하는 프로세스들이 네트워크에 의해 연결된 다른 컴퓨터들에 존재할 수 있는 **분산 환경** 에서 특히 유용하다.  

> 메시지 전달(send/receice) 연산 구현 방법 

- 직접 또는 간접 통신
- 동기식 또는 비동기식 통신
- 자동 또는 명시적 버퍼링

</br>

## 원격 프로시저 호출(Remote Procedure Calls, RPC)

</br>
네트워크에 연결되어 있는 두 시스템 사이의 통신에 사용하기 위하여 프로시저 호출을 추상화 하기 위한 방편으로 설계되었다.  
프로세스들이 서로 다른 시스템에서 실행 되기 때문에 원격 서비스를 제공하기 위해서는 **메시지 기반 통신** 을 해야한다.  

- 메시지 기반 통신
- 클라이언트에게 stub(스텁) 제공하여 자세한 사항을 숨긴다. 스텁이 원격 서버의 포트를 찾고 매개변수를 정돈(marshall) 한다.
- XDR(external data representation): 중립적 데이터 표현  

RPC의 경우 네트워크 오류 때문에 실패하고 메시지가 중복되어 호출이 여러번 실행될수도있다. 이때 해결 책은 OS에 의해 메시지가 최대 한번 실행되는 것이 아니라 **정확히 한번처리 되도록 보장** 하는 것이다.  

- 최대 한번을 고려
	- 메시지의 타임스탬프 기록을 갖거나 중복 메시지 검사를 위한 기록 필요
- 정확히 한번
	- 서버가 요청을 받았으면 "ACK(acknowledgement)" 메시지를 보내어 수신이 되었음을 알린다. 

</br>

<hr>

## CPU 스케줄러

스케줄링의 대상은 **Ready Queue** 에있는 프로세스 들이다. 

</br>

### FCFS(First-Come, First-Served Scheduling)- 선입 선처리 스케줄링

#### 특징

- 먼저 온 작업을 먼저 처리(서비스) 해주는 방식, 
- 비선점형(Non-Preemptive) 스케줄링
	- 	일단 CPU를 잡으면 CPU burst가 완료될 때까지 CPU를 반환하지 않는다. 할			당되었던 CPU가 반환될때만 스케줄링이 이루어 진다.

#### 문제점

</br>

- convoy effect: 소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다. 

</br>

### SJF(Shortes-Job-First)-최단작업 우선 스케줄링

#### 특징  

- 다른 프로세스가 먼저 도착했어도 CPU burst time 이 짧은 프로세스에게 선 할당
- 비선점형(Non-Preemptive) 스케줄링

#### 문제점

- starvatin(기아현상)
	- 효율성을 추구하는게 가장 중요하지만 특정 프로세스가 지나치게 차별받으면 안된다. 이 스케줄링은 극단적으로 CPU 사용이 짧은 Job을 선호한다. 그래서 사용 시간이 긴 프로세스는 거의 영원히 CPU를 할당 받을 수 없는 기아현상이 발생한다.
    
</br>

### SRT(Shortest Remaining Time First)-최소 잔여시간 우선 스케줄링

#### 특징  

- 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어 진다.
- 선점형(Preemptive) 스케줄링
	- 현재 수행중인 프로세스의 남은 burst time 보다 짧은 CPU burst time을 가지는 새로운 프로세스가 도착하면 CPU를 뺏긴다.

#### 문제점

- starvation(기아현상)
- 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.

</br>

### Priority Scheduling

#### 특징  

- 우선순위가 가장 높은 프로세스에게 CPU를 할당한다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.
- 선점형(Preemptive) 스케줄링
	- 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU를 선점한다.  
- 비선점형(Non-Preemptive) 스케줄링
	- 더 높은 우선순위의 프로세스가 도착하면 Ready Queue의 Head에 넣는다.

#### 문제점

- startvation(기아현상)
- Indefinite Bocking(무기한 봉쇄)
	- 실행 준비는 되어있으나 CPU를 사용 못하는 프로세스를 CPU가 무기한 대기하는 상태

#### 해결책

- Aging
	- 아무리 우선순위가 낮은 프로세스라도 오래 기다리면 운선순위를 높여주자
    
</br>

### Round Robin

#### 특징  

- 현대적인 CPU 스케줄링 
- 각 프로세스는 동일한 크기의 할당 시간(time quantum)을 갖게 된다.
- 할당 시간이 지나면 프로세스는 선점당하고 ready queue의 제일 뒤에 가서 다시 줄을 선다.
- Round Robin은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
- Round Robin이 가능한 이유는 프로세스의 context를 저장할 수 있기 때문이다.  

#### 장점  

- Reponse time(응답시간)이 빨라진다
	- n개의 프로세스가 ready queue에 있고 할당시간이 q(time quantum)인 경우 각 프로세스는 q단위로 CPU 시간의 1/n을 얻는다.즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
- 프로세스가 기다리는 시가닝 CPU를 사용할 만큼 증가한다. 즉 공정한 스케줄링이라 할 수 있다.  

#### 주의할 점  

설정한 time quantum 이 너무 커지면 FCFS(선입 선처리) 와 같아진다. 또 너무 작아지면 스케줄링 알고리즘 목적에는 이상적이지만 잦은 context switch로 오버헤드가 발생한다. 그렇기 때문에 **적당한 time quantum을 설정 하는 것이 중요하다.**


</br>

<hr>

## 동기(Sync) vs 비동기(Async)

동기와 비동기를 구분하는 기준은 **작업 순서** 이다.  
동기식 모델은 모든 작업들이 일련으 ㅣ순서를 따르며 그 순서에 맞게 동작한다. 즉 A,B,C순서대로 작업이 시작되었다면 A,B,C 순서로 작업이 끝나야 한다. 설령 여러 작업이 동시에 처리되고 있다고 해도, 작업이 처리되는 모델의 순서가 보장되면 이는 동기식 처리 모델이라고 할 수 있다.  

> 주의) 동기처리 모델에서 작업의 순서가 보장된다는 점 뿐이다. 다음 처리를 기다리는다는 것과는 다르다. 

동기식 처리 모델은 대부분의 프로세스 로직이고, 특히 Pipeline을 준수하는 Working Process에서 좋은 모델이다.  
반면 비동기식 모델은 **작업의 순서가 보장되지 않는다.**  
A,B,C순서로 작업이 시작되어도 A,B,C 순서로 작업이 끝난다고 보장할 수 없다.  
비동기식 처리 모델이 이득을 보는 경우는 각 작업이 분리될 수 있으며, Latency가 큰 경우이다. 예를들어 각 클라이언트 또는 작업 별로 Latency가 발생하는 네트워크 처리나 File I/O등이 훌륭한 적용 예시이다.  

## 블록킹(Blocking) vs 넌블로킹(Non-Blocking)  

블로킹과 넌블로킹을 구분하는 기준은 **통지** 이다.  
블로킹이란 말그대로 멈춤,대기(Wait)을 의미한다. 즉, 작업을 시작하고 **작업이 끝날때까지 대기하다가 즉석에서 완료 통지**를 받는다.  

> 주의) 작업이 멈추는 동안 다른 작업이 끼어들수 있는지 없는지는 다른 얘기이다. 즉 동기방식과 차이를 두는것이 동기는 순서가 중요, 블로킹은 작업을 수행하는데 대기시간만 갖을 뿐이다.  

넌블로킹이란 작업의 완료를 나중에 통지받는 개념이다. 작업의 시작 이 후 완료시 까지 대기하지 않고 완료시킨다. 즉 내부 동작에 무관하게 작업에 대한 완료를 처리받는걸 말한다. 
효과적인 작업 상태의 처리를 위해 넌블로킹에서는 **성공, 실패, 일부성공(partial sccess)** 라는 3가지 패턴이 존재한다.

</br>

## System I/O 

- Synchronous Blocking I/O : Application layer 의 계층이 Block을 일으키는 System Call을 호출하고, 이에 따라 User Layer와 Kernel Layer 간의 Context Switching 이 발생한다. 

이 때, Application 은 CPU 를 사용하지 않고 Kernel 의 응답을 기다리게 된다.

</br>

- Synchronous Non-blocking I/O : Nonblock Kernel Systemcall 을 사용하기 때문에 더 향상된 것처럼 보이지만, 

User Layer 가 Synchronous 이므로 응답을 기다리는 동안 Kernel 의 System Call을 Polling 하게 된다. 당연히 Context Switching 빈도수가 늘어나기 때문에 더 I/O에 지연이 발생하게 된다.

</br>

- Asynchronous Blocking I/O : User Layer의 I/O 가 Non-blocking 이고 Kernel 에서 알림이 블로킹 방식이다. Select System call 이 이 방식의 대표적이며 여러 I/O 를 한번에 수행할 수 있는 모델이다.

</br>

- Asynchronous Non-blocking I/O : Kernel I/O 의 개시와 알림 두 차례만 Context Switching 이 발생하고, Kernel 작업이 Non-block 이므로 select() 와 같은 멀티플렉싱 뿐 아니라 다른 프로세싱 자체가 가능하다. 

Kernel level 에서의 응답은 Signal 이나 Thread 기반 Callback 을 통해 user level 로 마치 이벤트처럼 전달된다.

[참고:jins-dev](https://jins-dev.tistory.com/entry/동기Synchronous-작업과-비동기Asynchronous-작업-그리고-블락Blocking-과-넌블락NonBlocking-의-개념)

</br>

## 프로세스 동기화

### Critical Section(임계영역)  

멀티 스레딩의 문제점에서 볼 수 있듯이, 동일한 자원을 동시에 접근하는 작업(e.g.공유하는 변수 사용, 동일 파일을 사용하는 등)을 실행하는 코드 영역을 Critical Section이라고 한다.  

</br>

### Critical Section Problem(임계영역문제)  

프로세스들이 Critical Section을 함께 사용할 수 있는 프로토콜을 설계하는 것이다.  
#### 임계 영역문제에 대한 해결안 3가지 요구조건  

- 상호배제(Mutial Exclusion)
	- 프로세스 P가 자기의 임계 영역에서 실행된다면 다른 프로세스들은 그들 자신의 임계영역에서 실행 될 수 없다. 
- 진행(Progress)
	- Critical Section 에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여 될 수 있다. 이 선택은 무기한 연기 될 수 없다. 
- 한정된 대기(Bounded Waiting)
	- 프로세스가 자기의 임계영역에 진입하려는 요청을 한 후부터 그 요청이 허용될 때까지 다른 프로세스들이 자신의 임계 영역에 진입 하도록 허용되는 횟수는 한계 또는 제한이 있어야 한다. 
        
</br>    
    
#### 선점형(Preemptive) vs 비선점형(Non-Preemptive)  

운영체제 내에서 임계영역을 다루기 위해서 두가지 일반적인 접근 방법이다.  

- 선점형 커널
	- 프로세스가 커널모드에서 실행되는 동안 선점되는 것을 허용한다.
    - 공유되는 커널 자료구조에서 경쟁 조건이 발생하지 않는다는 것을 보장하도록 설계 필요
    - 실시간 프로세스가 현캐 커널에서 실행 중인 프로세스를 선점할 수 있기 떄문에 **실시간 프로그래밍**에 적당하다.

</br>
    
- 비선점형 커널    
	- 커널모드에서 실행되는 프로세스의 선점을 허용하지 않고 커널모드 프로스세는 커널을 빠져나갈 때까지 또는 봉쇄될 떄까지 또는 자발적으로 CPU의 제어를 양보할 때까지 계속 실행한다.
    - 한 순간에 한 커널 안에서 실행 중인 프로세스가 하나 밖에 없기 떄문에 커널 자료구조에 대한 경쟁 조건을 염려할 필요 없다. 
    
</br>
    
### 해결책 


#### Lock

- 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section에 진입하는 프로세스는 Lock을 획득하고 Critical Section을 빠져나올 때, Lock 을 방출함으로써 동시에 접근이 되지 않도록 한다.  

##### 한계
- 싱글프로세서 환경에서는 공유 변수가 변경되는 동안 인터럽트 발생을 허용하지 않음으로써 간단히 해결할 수 있다.
- 멀티프로세서 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.
	- 인터럽트가 불능화 되었다는 메시지가 모든 프로세서에게 전달 되어야 하기 때문이다.
    

##### 구현

- `TestAndSet` 명령어
	- **원자적** 으로 실행되는 명령어(interrupt 되지 않는다)
    - false로 초기화 되는 lock이라는 boolean 변수를 선언하여 상호배제를 구현할 수 있다.
- `Swap()` 명령어
	- 두 개의 워드의 내용에 대해 작동한다.
    - 원자적으로 실행된다.
    - 전역 boolean으로 lock을 선언하고 false로 초기화한다. 각 프로세스는 지역 boolean 변수 key를 가지고있다.  
    
이 기법 들은 상호배제 조건은 만족시키지만 bounded waiting 조건은 만족 시키지 못한다.

> 참고) bounded waiting의 해결책으로 waiting list를 만들고 한 프로세스가 임계영역을 떠날때 이 배열에서 가능한 프로세스를 찾는 방법이다.

</br>

#### Semaphores(세마포)  

- 소프트웨어상에서의 Critical Section 문제를 해결하기 위한 도구
- 정수 변수로서 초기화를 제외하고는 단지 두개의 표준 원자적 연산 `wait()` 와 `signal()`로만 접근이 가능하다.

##### 카운팅 세마포

- **가용한 개수를 가진 자원**에 대한 접근 제어용으로 사용, 세마포는 그 가용한 자원의 개수로 초기화 된다. 자원을 사용하면 세마포 감소, 방출하면 세마포가 증가된다.

##### 이진 세마포(Mutex Lock)

- **MUTEX**라고 부르며,0 과 1 사이 값만 가능하며, 멀티프로세스들 사이의 Ciritical Section 문제를 해결하기 위해 사용한다.
     
##### 단점

- Busy Waiting
한 프로세스가 자신의 Critical Section에 있으면, 자신의 임계영역에 진입하려는 프로세스는 진입 코드를 계속 반복 실행해야 한다.이는 **CPU 시간을 낭비하게 된다.** 프로세스가 lock을 기다리는 동안 회전 하기 때문에 이런 타입의 세마포를 **spinLock**이라고도 부른다. 짧은 시간 동안만 소유될 것이 예상될 경우 spinLock이 유용하다.

- 싱글 프로세서 환경에서는 인터럽트를 금지 시킴으로서 해결 가능하다.
- 멀티 프로서서 환경에서는 모든 처리기에서 인터럽트를 금지해야한다 이는 성능을 심각하게 감소 시킨다.

##### DeadLock(교착상태)

- 세마포가 Ready Queue를 가지고 있고, 둘 이상의 프로세스가 Critical Section진입을 무한정 기다리고 있고, Critical Section에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되야만 빠져나올 수 있는 상황을 지칭한다.


### 모니터

- 고급언어의 설계 구조물로서, 개발자의 코드를 상호배제 하게끔 만든 추상화 된 데이터 형태이다.
- 공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다.(세마포는 직접 키 해제와 공유 자원 접근 처리가 필요하다)

</br>

<hr>

## 뮤텍스(Mutex) vs 세마포(Semaphores)

|뮤텍스(Mutex)|세마포(Semaphores)|
|:---|:---|
|공유된 자원의 데이터를 여러 **스레드**가 접근하는 것을 막는것|공유하는 자원의 데이터를 여러 **프로세스**가 접근하는 것을 막는것|
|뮤텍스는 lock,unlock 두가지의 값만 가진다|세마포는 1개이상의 스레드가 접근할 수 있다|
|프로세스의 범위(프로세스 존재시만 효력)|파일시스템 상 파일형태로 존재|
|소유 가능|소유불가능|
|뮤텍스를 소유하고 있는 쓰레드가 이 뮤텍스를 해제 할 수 있다.| 세마포어를 소유하고 있지 않는 쓰레드도 이 세마포어를 해제할 수 있다|

</br>


<hr>

## DeadLock(교착상태)

두 개 이상의 프로세스나 스레드가 서로의 자원을 기다리면서 무한히 기다리게 되는 상태이다. 멀티 프로그래밍 환경에서 한정된 자원을 사용하려고 경쟁하는 상황이다. 

### 교착 상태의 4가지 조건

1. Mutual Exclution(상호 배제): 자원은 한번에 하나의 프로세스만 접근 가능하다.  
2. Hold and Wait(점유 대기): 최소한의 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 있어야한다.  

3. No Preemption(비선점): 다른 프로세스에 할당된 자원은 사용이 끝날 떄까지 강제로 빼았을 수 없다.  

4. Circular Wait(순환 대기): 프로세스 집합 {P0, P1,, Pn)에서는 P0는 P1이 점유한 자원을 대기하고 P1은 P2,, ,, Pn은 다시 P0가 점유한 자원을 요구해야한다 마치 원형의 형태처럼 순환 구조를 이루어야 DeadLock이 발생한다.  

> Q) 교착 상태를 해결하는 방법? 전부다 종료하면 되는지?  

교착 상태가 발생한다면 회복을 위해 연관된 프로스세나 스레드 하나 또는 전부를 강제종료 한 뒤 재시작하게 되면 많은 비용이 발생한다. OS가 교착상태에 연관된 자원을 하나씩 강제로 Release를 하게한다. 위의 4가지 조건 중 최소 하나 이상을 시스템적으로 막아야한다. 위의 4가지 조건 중 하나라도 만족 하지 않으면 데드락이 아니다.

</br>

### DeadLock 처리 방법 3가지

위의 4가지 교착 상태 조건 중 하나를 부정 함으로서 교착상태를 처리 할 수 있다.  


1. 교착 상태 예방 및 회피(Avoid) 

교착 상태가 발생하지 않도록 예방하거나 회피하자.  
이 경우 프로세스가 사용할 자원에 대한 부가적인 정보를 미리 제공해야한다. 그래야 OS가 기다릴지 회피할지를 판단 할 수 있기 떄문이다. 

- 상호배제 부정: 여러개의 프로세스가 공유 자원을 사용할 수 있도록한다.
- 점유대기 부정: 프로세스가 실행되기 전 필요한 모든 자원을 할당한다.
- 비선점 부정: 자원을 점유하고 있는 프로세스가 다른 자원을 요구할 때 **점유하고 있는 자원을 반납하고 나서 요구한 자원을 사용하기 위해 기다린다.**(다른 걸 쓸려면 내것을 내려놓고 써야한다는 말이다)
- 순환대기 부정: 자원에 고유한 번호를 할당하고 번호 순서대로 자원을 요구하게 한다.

#### 뱅커스 알고리즘  

프로세스가 자원을 요구할 때 시스템은 자원을 할당한 후에도 * 안전 상태로 남아있게 되는지를 사전에 검사해서 교착상태를 회피 하는 방법이다.  

> 안전상태(Safe State): 시스템이 어떤 순서로든 프로세스들이 요청하는 모든 자원을 교착상태 발생없이 할당해줄수 있는 상태를 말한다. 

프로세스는 자원을 할당받기 전에 자신이 필요로 하는 자원수를 알려줘야 하고 요구한 자원의 수가 현재 사용가능한 자원의 수보다 작을 때만 할당하는 방식이다.  

2. 교착 상태 탐지 및 회복

#### 탐지

- 자원 할당 그래프를 통해 교착상태를 탐지한다. 하지만 지속 될 경우 오버헤드가 발생하고 싸이클이 존재 여부에 따라 교착상태 판단할 수 있다.(존재 -> 데드락)

#### 회복 

- 프로세스 종료
	- 교착상태 프로세스를 모두 중지: 이 방식은 비용이 크다. 계산 도중인 결과들을 폐끼 하고 나중에 다시 계산해야 하기 때문이다.
    - 교착상태가 제거될 때까지 한 프로세스 씩 중지: 검색 시 상당한 오버헤드 유발  
    
- 자원 선점
	- 자원을 선점해서 회복을 하는 방법이 있다. 교착상태의 프로세스가 점유하고 있는 자원을 뺏어서 다른 프로세스에게 할당한다(e.g. 우선순위가 낮은 프로세스의 자원을 선점해서 교착회복)
    - 희생자 선택
    - 롤백: 프로세스를 안전한 상태로 롤백 시키고 그 상태로 부터 다시 시작하는 방식 하지만 모든 프로세스들의 상태에 대한 보다 많은 정보를 유지할 것을 필요로 한다.
    - 기아상태 : 동일한 프로세스가 항상 희생자로 지목 될 수 있기 때문에 한정된 시간동안만 회생자를 지목하고 기아를 예방하는 방법이다. 대부분의 일반적인 해결방법은 비용 요소에 롤백의 횟수를 포함시키는 방법이다. 


3. 교착 상태 무시  

교착 상태를 탐지하고 복구하는 알고리즘이 없으면 계속해서 자원이 점유되어있는 곳에 많은 프로세스들이 요청을 하게 되고 결국 시스템 성능을 저하시키게 된다 **하지만** 대부분의 교착상태는 드물게 나타나고 지속적으로 사용해야하는 교착상태 예방, 교착상태 회피 또는 탐지와 복구 방법들 보다 **무시의 방법이 더 적은 비용이 든다.**  

</br>

<hr>

## 메모리 관리 전략  

### 기본 하드웨어  

모든 실행되는 명령어와 데이터들은 **CPU가 직접적으로 접근할 수 있는 주메모리와 레지스터에 있어야한다.** 만약 데이터가 메모리에 없다면 CPU가 그것들을 처리하기 전에 메모리로 이동시켜야 한다.  
  
CPU에 내장되어있는 레지스터 들은 일반적으로 `1 Clokc - 1 Cycle`내에 접근이 가능하다. 대부분의 CPU들은 레지스터에 있는 명령어의 해독과 간단한 연산을 클록 틱당 하나 또는 이 이상의 속도로 처리한다. 그러나 메모리 버스를 통해 전송되는 주메모리의 경우는 접근을 완료하기 위해서는 **만은 CPU 클록 틱 사이클이 소요**되고, 이 경우 **CPU가 필요한 데이터가 없어서 명령어를 실행하지 못하고 지연되는 Stall현상이 발생**한다.  

  
  즉 CPU 레지스터는 처리속도가 빠른데 주 메모리는 느리기 때문에 Stall 현상이 발생하게 되고 이를 해결하기 위해 **CPU 와 주메모리 사이에 빠른 속도의 메모리를 추가**하는것이다. **캐시(cache)** 라고 부르는 메모리 버퍼를 사용한다.  
  
- 목적: 물리 메모리의 상대적인 접근 속도의 차이에 대한 고려, 사용자 프로그램으로부터 운영체제 영역을 **보호**하고, 다른 사용자 프로그램이 특정 사용자 프로그램을 접근을 막는 것도 함께 이루어져야하며 하드웨어가 반드시 이를 지원해야한다.  

1. 각각의 프로세스는 독립된 메모리 공간을 가진다.  
	 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. **기준 과 상한**이라고 불리는 레지스터로 보호를 한다.  

2. 메모리 공간의 보호는 CPU하드웨어가 **사용자모드**에서 만들어진 모든 주소와 레지스터를 비교함으로써 이루어진다.  
	 사용자 모드에서 실행되는 프로그램에의해 운영체제의 메모리 공간이나 다른사용자 프로그램의 메모리 공간에 접근이 일어나면 운영체제는 치명적인 에러로 간주하고 **Trap**을 발생시킨다. 이는 앞에서 설명한거처럼 모든 특권 명령은 커널모드에서 실행이 되어야한다.
     - 커널 모드에서 실행되는 운영체제는 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 어떠한 제약도 받지않는다. 그 이유는 멀티프로세서 환경에서 프로세스의 현재 상태를 저장하고 다른 프로스세스의 상태를 가져오는 Context Switch 작업이 진행 되어야 하므로 이는 커널모드에서 실행이 되어야 하므로 모든 메모리 영역의 접근에 제약이 없어야한다.  
     
### Swapping  

메모리 관리를 위해 사용되는 기법 중 하나다. 표준 Swapping 방식으로는 Round-Robin 과 같은 스케줄링의 다중 프로그래밍 환경에서 CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(e.g. 하드디스크)로 내보내고 다른 프로세스의 메모리를 불러 들일 수 있다.  

- swap-in : 주 기억장치(RAM)으로 불러오는 과정
- swap-out : 보조 기억장치로 내보내는 과정  

##### swapping issue

Swapping 작업은 큰 디스크 전송 시간이 필요하므로 현재에는 **메모리 공간이 부족할때** 시작된다고 보면된다. 이떄 긴 swapping 시간, 작은 실행시간 즉 **현명한 메모리 관리가 필요하다.**  

- 한도를 정해 그 이하는 Swapping을 하지 않는 방법
- 일부분만 swapping하여 swapping 시간 줄이기  

</br>

### 연속 메모리 할당(CMA) 

메모리는 일반적으로 두개의 부분으로 나누어진다.  

- 메모리에 상주하는 운영체제를 위한 것
- 사용자 프로세스를 위한 것  

이 결정에 중요한 요인은 **인터럽트 벡터**이다. 

- Limit, Base 레지스터를 사용하여 사용할  수 있는 크기를 나타낸다.  

### 동적 메모리 할당 문제  

![image](https://user-images.githubusercontent.com/33486820/57308981-3c89c780-7122-11e9-9e59-b95864ec662d.png)  

- 최초 적합: 맨앞의 hole에 최적의 Process 할당 -> 시간이 빠르다.  
- 최적 적합: 전체 memory hole에서 가장 최적의 Process 할당 -> 잔여 공간 즉 Hole의 잔여가 작다.
- 최악 적합: 가장 큰 가용 공간을 택한다.  

### 단편화(Fragmentation)  

프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 작은 자유공간들이 늘어나게 되는 것을 말한다.

#### 외부 단편화

메모리 공간 중 사용하지 못게되는 일부분이다. 물리 메모리(RAM)에서 사이사이 남는 공간들을 모두합치면 충분한 공간이 되는 부분들이 **분산되어 있을때 발생한다**.  

![image](https://user-images.githubusercontent.com/33486820/57311271-43b2d480-7126-11e9-9d6a-d330458e1e3d.png)  

#### 내부 단편화  

프로세스가 사용하는 메모리 공간에 포함된 남는 부분이다.  

![image](https://user-images.githubusercontent.com/33486820/57311340-6a710b00-7126-11e9-81dd-ecdedd817418.png)  

#### Compaction(압축)

외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유공간을 확보하는 방법론이지만, 작업 효율이 좋지않다. 그렇기 때문에 프로세스들의 재배치가 실행시간에 동적으로 이루어지는 경우에만 가능하다.  




